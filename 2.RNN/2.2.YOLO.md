Architectures like faster R-CNN are accurate, but the model itself is quite complex, whith multiple outputs that are each a potential source of error.

And once traned they're still note fast enough to run in real time.

YOLO (You only look once), it's a real-time object detection algorithm, that avoid spending too much time on gerneating region proposals.

Instead of locating objects perfectly, it prioritizes speed and recognition.

## YOLO output
在之前我们看到，分类的输出和bounding的输出是通过加权求和的方式来计算的（a weighted combination of cassification and regression losses.）

Another way to process these outputs is by merging them into a single output vector, which is what the YOLO algorithm does.

We can identify an object in am image within a bounding box, by adding some box parameters to our CNN output vector. We can add 4 more numbers: x,y,w,h.

**(x,y)** determine the coordinates of the center of the box, **(w,h)** determine its width and height.

Once you've trained your CNN to output class probabilities and bounding box coordinates, you're one step closer to being able to detect objects in any given image.

## CNN & Sliding Window
![sliding window](../assets2/sliding_window_output.png)
`Pc` is a probability between zero and one, then an object exists within the window at all. If no object is detected, we don't have to proceed with trying to classify that particular region of the image.

比如一张16x16x3的图片，我们用一个10x10的窗口，stride=2来扫过整张图片，我们会得到16个小的区域，把这些区域分别单独作为输入传入CNN来分类和bounding，就是滑动窗口。

而实际上，CNN的最后一层输出，比如说是4x4x8，当16个窗口分别通过后，把这16个输出拼起来，可以看做是一个全新的CNN的输出。
![sliding window](../assets2/sliding_window.png)

因此，让这16个窗口单独通过旧的CNN，和用整张图片一次性通过某个新的CNN，效果是一样的。

This is how you can apply sliding windows with a CNN. This technique makes the whole process much more efficient. However, this technique has a downside: the position of the bounding boxes is not going to be very accurate. The reason is that it is quite unlikely that a given size window and stride will be able to match the objects in the images perfectly. In order to increase the accuracy of the bounding boxes, YOLO uses a grid instead of sliding windows, in addition to two other techniques, known as `Intersection Over Union` and `Non-Maximal Suppression`.

## YOLO
The implementation of sliding windows is very slow, but it can be faster if you choose a stride so that each window convers a new part of an image and there's no overlap.

Inspired by this approach, YOLO uses a grid instead of sliding windows.

### train
For each training image
* Break into a grid
* Manually assign a ground truth vector to each grid cell (like sliding window)

Then is to design a CNN that can be trained using these vectors.

How does YOLO find a correct bounding box when it looks at an image broken up by grid?

The trick is that it assigns the ground-truth bounding box for one object in an image to only one grid cell in the training image.(在一张图片中，对于一个待检测的物体，只标记一个格子).

So, only one grid cell is meant to locate the object.

For each training image
* Locate the mid-point of each object in the image
* Assign the true bounding box to grid cell that contains that mid-point

![yolo grid](../assets2/yolo_grid.png)
只有中间有黄点的粉红色各自带有`Pc=1`的标记，其他的比如上面的紫色的各自，即使也是人的一部分，`Pc也是为0`

In YOLO, (x,y) determine the coordinates of the center of the bounding box **relative to the grid cell**, and (w,h) determine the width and the height of the box relative to **the whole image**.

The convention is that the upper left corner of a grid cell has (0,0), the bottom right hand corner has coordinates (1,1).
So, in this example shown below, the centre point relative to the grid cell coordinate system is `(x,y) = (0.5, 0.3)`, and `(w,h) = (0.1, 0.4)`, because width is abount 10% the width of **the entire image** and the height h is about 40%.
![yolo grid vector](assets/yolo_grid_vector.png)

x,y,w,h is all between 0 and 1. This technique is very similar to normalization.

By standardizing the range of these values, this algorithm becomes easier to train and converge to a smaller error.

But there's one problem whis this method.

The truth is, one of the problems with this method is that the CNN will often output multiple gird cells that try to detect the same object. So, any of these cells might try to detect the person and we might end up with multiple bounding boxes for the same person.

### Too Many Boxes
To account for this, we use a technique called **non-maximal suppression（非最大抑制）**, which tried to find the bounding box that best mnathes an object in an image(它试图找到与图像中的对象最匹配的边界框).

### IoU, Intersection over Union
Before learning about non-maximal suppression, we'll need to learn about intersection over union or IoU, which is a technique used in non-maximal suppression to compare how good two different bounding boxes are for a given object.
$$ IOU = \frac{Area\ of\ Intersection}{Area\ of\ Union\ of\ Both\ Rectangles} $$

The area of intersection between the two boxes is marked by the green rectangle and it's just the area where these boxes overlap.(两个边界之间的相交区域，是这两个box重叠的区域)

The area of the union is denoted by the purple area and is the total area of the boxes if they were smooched into one bigger unified shape.（Union，是boxex的总面积，如果他们连成一个更大的统一形状的话）

![IOU](../assets2/IOU.png)

![IOU2](../assets2/IOU2.png)

### Non-maximal Suppression
设定一个threshold，抛弃小于阈值的box，然后在剩下的boxex里面选取Pc最大的。

## Anchor Boxes
What about in the case of overlap, in which one grid cell actually contains the center points of two different objects?

We can use something called anchor boxes to allow one grid cell to detect multiple objects.

In this image, we see that we have a person and a car overlapping in the image. So, part of the car is obscured. We can also see that the centers of both bounding boxes, the car and the pedestrian fall in the same grid cell.

Since the output vector of each grid cell can only have one class, then it will be forced to pick eigher the car or the person.

But by defining anchor boxes, we can create a longer grid cell vector and associate multiple classes with each grid cell.

So the outout vector will now contain `16` elements(8 for each object box)

But it can only associate one object with each type of anchor box, so it doesn't work very well if you have two overlapping objects that are roughly the same shape. Similarly, if you only define two anchor boxes but have three overlapping objects, then this algorithm fails because it will be forced to identify only two of the objects. The good news is that the above cases are womewhat rare.

### How YOLO works
Once the CNN has been trained, we can now detect objects in images by feeding at new test images.

The test image is first broken up into a grid and the network then produces output vectors, one for each grid cell. These vectors tell us if a cell has an object in it, what class the object is, and the bounding boxes for the object. If we uses two anchor boxes, we'll get two predicted anchor boxes for each grid cell. Some, in fact most of the predicted anchor boxes will have a very low Pc value.

After producing these output vectors, we use non-maximal suppression to get rid of unlikely bounding boxes. For each class, non-maximal suppression gets rid of the bounding boxes that have a Pc value lower than some given `threshold`. It then selects the bounding boxes with the highest Pc value, and removes bounding boxes that are too similar to this. It will repeat this until all of the non-maximal bounding boxes had been removed for every class.
