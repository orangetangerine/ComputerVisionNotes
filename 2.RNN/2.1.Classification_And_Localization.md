# regression losses
## L1 Loss
You may consider that L1 loss can become negligible for small error values
## MSE Loss

MSE loss responds the most to large errors, and so it may end up amplifying errors that are big but infrequent. Also known as outliers

## Smooth L1 Loss
There's also Smooth L1 Loss which for small diferences between predicted and true values, uses a squared error function, and for larger errors uses L1 Loss.
So Smooth L1 loss try to combine the best aspects of MSE and L1 loss.


# Classification and Localization
![Classification and Localization](../assets2/classification_and_localization.png)

You may be wondering: how can we train a network with two different outputs (a class and a bounding box) and different losses for those outputs?

We know that, in this case, we use categorical cross entropy to calculate the loss for our predicted and true classes, and we use a regression loss (something like smooth L1 loss) to compare predicted and true bounding boxes. But, we have to train our whole network using one loss, so how can we combine these?

There are a couple of ways to train on multiple loss functions, and in practice, we often use a weighted sum of classification and regression losses (ex. `0.5*cross_entropy_loss + 0.5*L1_loss`); the result is a single error value with which we can do backpropagation. This does introduce a hyperparameter: the loss weights. We want to weight each loss so that these losses are balanced and combined effectively, and in research we see that another regularization term is often introduced to help decide on the weight values that best combine these losses.

## Multiple objects
如果在一张图片内有多个目标怎么办呢？假设有一张图片有两个目标：
* 可以把图片分成两个区域，每个区域只包含一个待检测的object。然后可以把每个region通过cnn。问题是，输出的数量的可变的，就是说我们不知道图片中有多少个目标需要被检测，而CNNs和大部分神经网络都是固定的预先设置好的输出大小（output size）。这里可以定义一个sliding window然后扫过整个图片，得到很多原图片的小区域；然后对于每一个区域，我们把它通过CNN然后分类。可是这有太多太多区域了，非常耗时！何况还有很多区域是没有要检测的目标的！

The regions we want to analyze are those with complete objects in them. We want to get rid of regions that contain image background or only a portion of an object. So, two common approaches are suggested:
1. identify similar regions using feature extraction or a clustering algorithm like k-means, as you've already seen; these methods should identify any areas of interest.
2. Add another layer to our model that performs a binary classification on these regions and labels them: object or not-object; this gives us the ability to discard any non-object regions!

## Region Proposals
Region proposals give us a way to quickly look at an image and generate regions only for areas in which we think there may be an object.

We can use traditional computer vision techniques that detect things like edges and textured bobs to produce a set of regions in which objects are most likely to be found; areas of similar texture or the same unifying boundary, for example.
These proposals often produce noisy non-object regions, but they are also very likely to include the regions in which objects are located. So the noise is considered a worthwhile cost for not missing any objects. Let's see how this looks when incorporated into a CNN architecture.

We can use a region proposal algorithm to produce a limited set of copped regions. Often called regions of interests or `ROIs`. And then we put these regions through a classification CNN, one at a time and see what kind of class label the network predicts for each crop. This model is called an `R-CNN`. Which stands for region convolutional neural network. The R-CNN produces a class for each region of interest, and so it can identify the region that is a dog and the region that is a cat in an image. We can also include a class called background, that's meant to capture any noisy regions.

Since these regions are often different sizes they first need to be transformed and warped into a standard size that a CNN can accept as input.

The main shortcoming of this method is that it still time intensive because it required that each cropped region go through an entire CNn before a class label can be produced.
We can see some examples of region-based CNNs that aim to speed up this process and efficiently classify multiple objects in an image.

#### R-CNN Outputs
The R-CNN is the least sophisticated region-based architecture, but it is the basis for understanding how multiple object recognition algorithms work! It outputs a class score and bounding box coordinates for every input RoI.

An R-CNN feeds an image into a CNN with regions of interest (RoI’s) already identified. Since these RoI’s are of varying sizes, they often need to be warped to be a standard size, since CNN’s typically expect a consistent, square image size as input. After RoI's are warped, the R-CNN architecture, processes these regions one by one and, for each image, produces 1. a class label and 2. a bounding box (that may act as a slight correction to the input region).

1. R-CNN produces bounding box coordinates to reduce localization errors; so a region comes in, but it may not perfectly surround a given object and the output coordinates (x,y,w,h) aim to perfectly localize an object in a given region.

2. R-CNN, unlike other models, does not explicitly produce a confidence score that indicates whether an object is in a region, instead it cleverly produces a set of class scores for which one class is "background". This ends up serving a similar purpose, for example, if the class score for a region is Pbackground = 0.10, it likely contains an object, but if it's Pbackground = 0.90, then the region probably doesn't contain an object.


## Fast R-CNN
Instead of processing each region of interest individually through a classification CNN, this architecture runs the entire image through a classification CNN only once.

The image goes through a series of convolutional and pooling layers and at the end of these layers, we get a stack of feature maps.

We still need to identify regions of interest bt instead of cropping the original image, we project these proposals into the smaller feature map layer.

Each region in the feature map corresponds to a larger region in the original image.
So we can grab selected regions in this feature map and feed them one by one in to a fully connected layer that generates a class for each of these different regions.
In this model we complete the mose time-consuming steps, processing an image through a series of convolutional layers only once and then selectively use that map to get our desired outputs.
Again, we have to handle the variable sizes and these protections, since layers further in the network are expecting input of a fixed size. So, we do something called `RIO polling` to warp these regions into a consistent size before giving them to a fully connected layers.
![roi pooling](../assets2/roi_pooling.png)

#### Speed
Fast R-CNN is about 10 times as fast to train as an R-CNN because it only creates convolutional layers once for a given image and then performs further analysis on the layer. Fast R-CNN also takes a shorter time to test on a new image! It’s test time is dominated by the time it takes to create region proposals.

## Faster R-CNN
To speed up the time it takes to run a test image through a network and detect all the objects in it, we want to decrease the time it takes to form region proposals. For this we have the faster R-CNN architecture.

Faster R-CNN learns to come upwith its own region proposals. It takes in an input image, runs it through a CNN up unitl a certain convolutaional layer just like Fast R-CNN, but this time it uses the produced feature map as input into a separate `region proposal network(RPN)`. So it predicts its own regions from the features produced inside the network. If an area in the feature map is rich in detected edges or other features, it's identified as a region of interest. Then this part of a network does a quick binary classification. For each ROI it checks whether or not that region contains an object. If it does then region will continue on and go through the classification steps, and if it doesn't, then the proposal is discarded.

Once we have the final region proposals, the rest of the network looks the same as Fast R-CNN. It takes cropped regions from the feature map and learns to classify those regions.

By eliminating the analysis of non-object regions, this model is the fastest fo all the region-based CNNs that we've seen.

#### Region Proposal Network
You may be wondering: how exactly are the RoI's generated in the region proposal portion of the Faster R-CNN architecture?

The region proposal network (RPN) works in Faster R-CNN in a way that is similar to `YOLO(You only look once)` object detection, which you'll learn about in the next lesson. The RPN looks at the output of the last convolutional layer, a produced feature map, and takes a sliding window approach to possible-object detection. It slides a small (typically 3x3) window over the feature map, then for each window the RPN:

1. Uses a set of defined anchor boxes, which are boxes of a defined aspect ratio (wide and short or tall and thin, for example) to generate multiple possible RoI's, each of these is considered a region proposal.
2. For each proposal, this network produces a probability, Pc, that classifies the region as an object (or not) and a set of bounding box coordinates for that object.
3. Regions with too low a probability of being an object, say Pc < 0.5, are discarded.
Training the Region Proposal Network
Since, in this case, there are no ground truth regions, how do you train the region proposal network?

The idea is, for any region, you can check to see if it overlaps with any of the ground truth objects. That is, for a region, if we classify that region as an object or not-object, which class will it fall into? For a region proposal that does cover some portion of an object, we should say that there is a high probability that this region has an object init and that region should be kept; if the likelihood of an object being in a region is too low, that region should be discarded.

I'd recommend this [blog post](https://towardsdatascience.com/deep-learning-for-object-detection-a-comprehensive-review-73930816d8d9) if you'd like to learn more about region selection.


#### Speed Bottleneck
Now, for all of these networks including Faster R-CNN, we've aimed to improve the speed of our object detection models by reducing the time it takes to generate and decide on region proposals. You might be wondering: is there a way to get rid of this proposal step entirely? And in the next section we'll see a method that does not rely on region proposals to work!

#### Faster R-CNN Implementation
If you'd like to look at an implementation of this network in code, you can find a peer-reviewed version, at [this Github repo](https://github.com/jwyang/faster-rcnn.pytorch).

### YOLO(You only look once) / SSD(single shot detection)
